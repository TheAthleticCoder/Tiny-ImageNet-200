{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-Detect-Final-Code-Submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPsWgwryraFn9nF0oJOn0ZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshit-collab/Tiny-ImageNet-200/blob/master/Image_Detect_Final_Code_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY4d1EpO3HjX",
        "colab_type": "text"
      },
      "source": [
        "# **Accessing The Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoOzVN6d3eSr",
        "colab_type": "text"
      },
      "source": [
        "Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE_QjnOEVRSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8f178cf4-75f7-4e86-a18b-55f8571e94c5"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7wwQa1x3l9_",
        "colab_type": "text"
      },
      "source": [
        "Extracting required files from the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_aDIoOBVVQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/gdrive/My Drive/image-detect.zip') as zf:\n",
        "  zf.extractall('/content')\n",
        "train_location = '/content/image-detect/train/'\n",
        "test_location  = '/content/image-detect/test/'\n",
        "valid_location = '/content/image-detect/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwvO1SNy4J-K",
        "colab_type": "text"
      },
      "source": [
        "## **Importing The Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEjeqWPBpQcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87883327-81bb-401b-8c10-d2ff94b77b00"
      },
      "source": [
        "import time\n",
        "import scipy.ndimage as nd\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import six\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import ( Input, Activation, Dense, Flatten )\n",
        "from keras.layers.convolutional import ( Conv2D, MaxPooling2D, AveragePooling2D )\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
        "\n",
        "\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.activations import softmax\n",
        "from keras.models import load_model \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCqUCFPThGrc",
        "colab_type": "text"
      },
      "source": [
        "# **Dictionaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpSOpKrJ4rLb",
        "colab_type": "text"
      },
      "source": [
        "Now, we create necessary dictionaries to utilise the data in an organised fashion-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrNQcLKr4juW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = #type in path (eg-../input/image-detect/)\n",
        "\n",
        "def id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def data(id_dict):\n",
        "    print('loading dataset')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(450)]\n",
        "        train_labels_ = np.array([[0]*200]*450)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread( path + 'val/images/{}'.format(img_name) ,pilmode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading dataset, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = data(id_dictionary())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYSylLRyhik1",
        "colab_type": "text"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOhsWk7YJLYI",
        "colab_type": "text"
      },
      "source": [
        "Shuffling the data and its respective labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQJtMWedJKXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_data(train_data, train_labels ):\n",
        "    size = len(train_data)\n",
        "    train_idx = np.arange(size)\n",
        "    np.random.shuffle(train_idx)\n",
        "\n",
        "    return train_data[train_idx], train_labels[train_idx]\n",
        "  \n",
        "train_data, train_labels = shuffle_data(train_data, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNB4Z72NdqRj",
        "colab_type": "text"
      },
      "source": [
        "Creating the model-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iCQzLMQWxk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.common.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.common.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
        "                      activation=\"softmax\")(flatten1)\n",
        "\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09J-iIKbTT2i",
        "colab_type": "text"
      },
      "source": [
        "Introducing callbacks and initializing required variables-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXYGRiOxR42P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "early_stopper = EarlyStopping(min_delta=0.0001, patience=10)\n",
        "csv_logger = CSVLogger('resnet50_tiny_ImageNet.csv')\n",
        "\n",
        "batch_size = 250\n",
        "nb_classes = 200\n",
        "nb_epoch = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "#RGB channels\n",
        "img_channels = 3\n",
        "\n",
        "X_train = train_data\n",
        "Y_train = train_labels\n",
        "X_test = test_data\n",
        "Y_test = test_labels\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# subtract mean and normalize\n",
        "mean_image = np.mean(X_train, axis=0)\n",
        "#X_train -= mean_image\n",
        "#X_test -= mean_image\n",
        "X_train /= 256.\n",
        "X_test /= 256.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKA_yupzTdNZ",
        "colab_type": "text"
      },
      "source": [
        "Compiling the required ResNet Model-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ8M_SvOTcl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResnetBuilder.build_resnet_''''enter model number required i.e. 18,34,50,101,152'''((img_channels,img_rows, img_cols), nb_classes,weight_decay=1e-3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCTr91VjR2WM",
        "colab_type": "text"
      },
      "source": [
        "Seeing model summary-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUEvCAjkQ_Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XctdQucTPkyj",
        "colab_type": "text"
      },
      "source": [
        "Saving model image for easier viewing and understanding-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nhh5du4Pfnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFIoARCUQ-3f",
        "colab_type": "text"
      },
      "source": [
        "Using Datagen Flow-\n",
        "Rather than performing the operations on your entire image dataset in memory, the API is designed to be iterated by the deep learning model fitting process, creating augmented image data for you just-in-time. This reduces your memory overhead, but adds some additional time cost during model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWQ8YctWPkFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Using data augmentation to enhance data')\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,           # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,            # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,# divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False, # divide each input by its std\n",
        "          zca_whitening=False,                # apply ZCA whitening\n",
        "          rotation_range=0 ,                 # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          width_shift_range=0.1,              # randomly shift images horizontally (fraction of total width)\n",
        "          height_shift_range=0.1,             # randomly shift images vertically (fraction of total height)\n",
        "          horizontal_flip=True,               # randomly flip images\n",
        "          vertical_flip=False )               # randomly flip images\n",
        "\n",
        "# Compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit( X_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfgwTGlSMDad",
        "colab_type": "text"
      },
      "source": [
        "Training the model in small epochs of size 10 each and repeatedly saving to prevent running out of RAM. To train further, we simply load the model and continue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOSHKwq2L_JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epoch = 10 # epoch 1-10\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator( datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                     steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                     validation_data=(X_test, Y_test),\n",
        "                     epochs=nb_epoch, verbose=1, callbacks=[lr_reducer, early_stopper, csv_logger]\n",
        "                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxszXD94NDmd",
        "colab_type": "text"
      },
      "source": [
        "In order to plot the training and validation accuracy and losses we use the code-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDEx-lAnNB4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epoch = 10 # epoch 1-10\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "history = model.fit_generator( datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                     steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                     validation_data=(X_test, Y_test),\n",
        "                     epochs=nb_epoch, verbose=1, callbacks=[lr_reducer, early_stopper, csv_logger]\n",
        "                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cArrNaC5NPhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeQzeNsmMgH0",
        "colab_type": "text"
      },
      "source": [
        "Code for saving the model-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfrDwz03Mel7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs_passed = 10 #number of epochs passed(10 in this case)\n",
        "model.save_weights( 'model_weights_after_%s_epoch.h5' % epochs_passed )\n",
        "model.save( 'resnet_modified_model.h5' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-NkxNC_Mthh",
        "colab_type": "text"
      },
      "source": [
        "Code for loading the saved model-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMOU0xfzMrhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "epochs_passed = 10\n",
        "\n",
        "# Returns a compiled model identical to the previous one\n",
        "model = load_model( 'resnet_modified_model.h5')\n",
        "model.load_weights( 'model_weights_after_%s_epoch.h5' % epochs_passed )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo-vv1bLNBeI",
        "colab_type": "text"
      },
      "source": [
        "Code for running model again with more epochs-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ981OSxMdCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_epoch = 10 # epoch 11-20\n",
        "# Fitting the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    epochs=nb_epoch, verbose=1, \n",
        "                    callbacks=[lr_reducer, early_stopper, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zm2ZkVqhnGq",
        "colab_type": "text"
      },
      "source": [
        "## **Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSV_ZzLFNabW",
        "colab_type": "text"
      },
      "source": [
        "Downloading the testing data to make predictions and preprocessing it-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmxwKvdfNJEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('loading final data')\n",
        "final_data = []\n",
        "final_labels = []\n",
        "t = time.time()\n",
        "for i in ids:\n",
        "    final_data.append(imageio.imread( path + 'test/images/{}'.format(i), pilmode='RGB'))\n",
        "    \n",
        "print('finished loading final data, in {} seconds'.format(time.time() - t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adlzyEi1NnRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data = np.array(final_data)\n",
        "final_data = final_data.astype('float32')\n",
        "\n",
        "\n",
        "# subtract mean and normalize\n",
        "mean_image = np.mean(final_data, axis=0)\n",
        "#final_data -= mean_image\n",
        "\n",
        "final_data /= 256."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed6VLZBONuk_",
        "colab_type": "text"
      },
      "source": [
        "Making predictions using the trained model and weights on the final data-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuhCaOt2Nzal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_final = model.predict(final_data)\n",
        "Y_final = np.argmax(Y_final,axis=1)\n",
        "Y_final_l = Y_final.tolist()\n",
        "dict = id_dictionary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KB-4u-mOBDi",
        "colab_type": "text"
      },
      "source": [
        "Using a small code snippet to switch the keys and values of a dictionary-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdLTdAloOAHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict = {value:key for key, value in dict.items()}\n",
        "print(dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO4jWmIuOIbz",
        "colab_type": "text"
      },
      "source": [
        "Reassigning all predictions to their respective values-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD1PFBfLOP_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "for i in Y_final:\n",
        "    predictions.append(dict.get(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E09GLu4hsVt",
        "colab_type": "text"
      },
      "source": [
        "## **Submission**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqZyWd9YOSjm",
        "colab_type": "text"
      },
      "source": [
        "Creating an acceptable csv file for submission-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXEgTWBfOXRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['category'] = predictions\n",
        "pre = test_df.rename(columns = {'Id':'file_name'})\n",
        "post = pre.drop(columns = ['ImageFileName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRIb5RK0OxvF",
        "colab_type": "text"
      },
      "source": [
        "Saving it in .csv format and submitting it-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXdH2-9-O4s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfUkz096gNvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}